{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from random import random\n",
    "import numpy as np\n",
    "import math\n",
    "from math import exp\n",
    "trainFileName = \"train.csv\"\n",
    "testFileName = \"test.csv\"\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDatasetFromCSV(fileName):\n",
    "    Data = []\n",
    "    with open(fileName, 'r') as file:\n",
    "        csvReader = reader(file)\n",
    "        next(csvReader, None)\n",
    "        for row in csvReader:\n",
    "            for i in range(1, 3):\n",
    "                row[i] = float(row[i].strip())\n",
    "            row[0] = int(row[0].strip())\n",
    "            Data.append(row)\n",
    "    # trainData = trainData[1:]\n",
    "    return Data\n",
    "\n",
    "#     firstRowFromCSV = trainData[0][1:]\n",
    "#     firstRowFromCSVOutput = trainData[0][0]\n",
    "def shuffleData(data):  \n",
    "    np.random.shuffle(data)\n",
    "    shuffleData = []\n",
    "    shuffledOutput = []\n",
    "    for row in data:\n",
    "        shuffleData.append(row[1:])\n",
    "        shuffledOutput.append(row[0])\n",
    "    return shuffleData, shuffledOutput\n",
    "\n",
    "# print(firstRowFromCSV)\n",
    "# print(firstRowFromCSVOutput)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(trainingData[i], trainingOutput[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetwork():\n",
    "    numInputs = 2\n",
    "    numHidden1 = 3\n",
    "    numHidden2 = 3\n",
    "    numOutput = 2\n",
    "    hiddenLayer1 = [{'w': [random() for i in range(numInputs)]} for i in range(numHidden1)]\n",
    "    # hiddenLayer1.append({'layer': 'hidden'})\n",
    "    hiddenLayer2 = [{'w': [random() for i in range(numHidden1)]} for i in range(numHidden2)]\n",
    "    # hiddenLayer2.append({'layer': 'hidden'})\n",
    "    outputLayer = [{'w': [random() for i in range(numHidden2)]} for i in range(numOutput)]\n",
    "    # outputLayer.append({'layer': 'output'})\n",
    "    neuralNetwork = [hiddenLayer1, hiddenLayer2, outputLayer]\n",
    "    return neuralNetwork\n",
    "    x=[]\n",
    "    W1 = []\n",
    "    W2 = []\n",
    "    W3 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotProduct(W, I):\n",
    "    a=0.0\n",
    "    for i in range(len(W)):\n",
    "       a+=W[i]*I[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxActivationFunction(inputs):\n",
    "    sum=0\n",
    "    retVal=[]\n",
    "    for i in range(len(inputs)):\n",
    "        sum+= exp(inputs[i])\n",
    "    retVal.append(exp(inputs[0]) / sum)\n",
    "    retVal.append(exp(inputs[1]) / sum)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reluActivationFunction(val):\n",
    "    return max(0, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(val, i):\n",
    "    if i==2:\n",
    "        return val * (1.0 - val)\n",
    "    else:\n",
    "        if val<=0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropogation(network, data, drop):\n",
    "#     print(network)\n",
    "    currentData = data\n",
    "    layerCount=0\n",
    "    softmaxInputs=[]\n",
    "    for layer in network:\n",
    "        layerCount+=1\n",
    "        nodeCount=-1\n",
    "        activatedValues = []\n",
    "        for node in layer:\n",
    "            nodeCount+=1\n",
    "            #If drop out - deactivate the node by setting output to 0\n",
    "            if (layerCount==1 and nodeCount==drop[0]) or (layerCount==2 and nodeCount==drop[1]):\n",
    "                node['o']=0.0\n",
    "                activatedValues.append(node['o'])\n",
    "                continue\n",
    "#             print(node['w'])\n",
    "            #Update to ignore the dropped node in second hidden layer\n",
    "#             if layerCount==2:            \n",
    "#                 prod = dotProduct(node['w'][:drop[0]]+node['w'][drop[0]+1:], currentData)\n",
    "#             else:\n",
    "            prod = dotProduct(node['w'], currentData)\n",
    "#             print(prod)\n",
    "            if(layerCount!=3):\n",
    "                node['o'] = reluActivationFunction(prod)\n",
    "#                 print(node['o'])\n",
    "                activatedValues.append(node['o'])\n",
    "            elif(layerCount==3):\n",
    "                softmaxInputs.append(prod)\n",
    "#                 print(\"Softmax:\", softmaxInputs)\n",
    "                if(len(softmaxInputs) == 2):\n",
    "                    activatedValues = softmaxActivationFunction(softmaxInputs)\n",
    "#                     print(\"activated: \", activatedValues)\n",
    "                    layer[0]['o'] = activatedValues[0]\n",
    "                    node['o'] = activatedValues[1]\n",
    "        currentData = activatedValues\n",
    "#     print(\"Summ Current Data: \", currentData[0], currentData[1])\n",
    "    return currentData, network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runForwardPropogation(nn, inputData, rowOutput, drop):\n",
    "    fwdOutput, network = forwardPropogation(nn, inputData, drop)\n",
    "#     print([trainData[0][:1], fwdOutput])\n",
    "    loss = 0\n",
    "    targetOutput=[]\n",
    "    if(rowOutput == 1):\n",
    "        targetOutput = [0, 1]\n",
    "    elif (rowOutput == 0):\n",
    "        targetOutput = [1, 0]\n",
    "    for i in range(2):\n",
    "        loss += pow((targetOutput[i] - fwdOutput[i]), 2)\n",
    "    return fwdOutput, loss, targetOutput, network\n",
    "    print(loss)\n",
    "# print(nn)\n",
    "#backwardPropogation(nn, targetOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardPropogation(network, targetOutput, drop):\n",
    "    #using reverse order, i=2,1,0\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        error=[]\n",
    "        #Output layer\n",
    "        if i == len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                e = 2 * (targetOutput[j] - neuron['o'])\n",
    "                error.append(e)\n",
    "        #other layers\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                #Dropout code\n",
    "                if (i==0 and j==drop[0]) or (i==1 and j==drop[1]):\n",
    "                    error.append(0.0)\n",
    "                    continue\n",
    "                err=0.0\n",
    "                for neuron in network[i+1]:\n",
    "                    err+=(neuron['w'][j] * neuron['e'])\n",
    "                error.append(err)\n",
    "        for j in range(len(layer)):\n",
    "            #Dropout code\n",
    "#             if i==0 and j==drop[0]:\n",
    "#                 continue\n",
    "            neuron=layer[j]\n",
    "            neuron['e'] = error[j] * derivative(neuron['o'], i)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBackwardPropogation(nn, targetOutput, inputData, learningRate, drop):\n",
    "    nn = backwardPropogation(nn, targetOutput, drop)\n",
    "#     for layer in nn:\n",
    "#         print(layer, '\\n\\n')\n",
    "    for i in range(len(nn)):\n",
    "        neuronCount=-1\n",
    "        inputVal=inputData\n",
    "        #Dropout code\n",
    "        if i!=0:\n",
    "            inputVal = [neuron['o'] for neuron in nn[i-1]]\n",
    "            #If dropped node, make input as 0\n",
    "#             if i==1:\n",
    "#                 inputVal[drop[0]]=0\n",
    "        for neuron in nn[i]:\n",
    "            neuronCount+=1\n",
    "            #Dropout code\n",
    "#             if i==0 and neuronCount==drop[0]:\n",
    "#                 continue\n",
    "            for j in range(len(inputVal)):\n",
    "#                 if i==2 and j==drop[0]:\n",
    "#                     continue\n",
    "                neuron['w'][j] += learningRate * neuron['e'] * inputVal[j]\n",
    "    return nn\n",
    "# for layer in nn:\n",
    "#     print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->epoch= 1 / 100   loss= 0.4974242798992358\n",
      "-->epoch= 2 / 100   loss= 0.4324176630302893\n",
      "-->epoch= 3 / 100   loss= 0.2981828488267208\n",
      "-->epoch= 4 / 100   loss= 0.27231193566771134\n",
      "-->epoch= 5 / 100   loss= 0.26826906744799817\n",
      "-->epoch= 6 / 100   loss= 0.27151466805576796\n",
      "-->epoch= 7 / 100   loss= 0.2632356884073203\n",
      "-->epoch= 8 / 100   loss= 0.2678581855267633\n",
      "-->epoch= 9 / 100   loss= 0.2620846893149713\n",
      "-->epoch= 10 / 100   loss= 0.2644163155026921\n",
      "-->epoch= 11 / 100   loss= 0.2607643923764768\n",
      "-->epoch= 12 / 100   loss= 0.26493126856452826\n",
      "-->epoch= 13 / 100   loss= 0.26397978985861464\n",
      "-->epoch= 14 / 100   loss= 0.2599409432234546\n",
      "-->epoch= 15 / 100   loss= 0.26554925401094903\n",
      "-->epoch= 16 / 100   loss= 0.2697038344908987\n",
      "-->epoch= 17 / 100   loss= 0.26515068671245384\n",
      "-->epoch= 18 / 100   loss= 0.2668386146543973\n",
      "-->epoch= 19 / 100   loss= 0.2623894718062597\n",
      "-->epoch= 20 / 100   loss= 0.2642390798362045\n",
      "-->epoch= 21 / 100   loss= 0.2663233119277206\n",
      "-->epoch= 22 / 100   loss= 0.2612577877158177\n",
      "-->epoch= 23 / 100   loss= 0.2625785950782991\n",
      "-->epoch= 24 / 100   loss= 0.25997249950174495\n",
      "-->epoch= 25 / 100   loss= 0.26192760573638796\n",
      "-->epoch= 26 / 100   loss= 0.26112183147050005\n",
      "-->epoch= 27 / 100   loss= 0.2588792953816115\n",
      "-->epoch= 28 / 100   loss= 0.26410599850460587\n",
      "-->epoch= 29 / 100   loss= 0.2621199290837839\n",
      "-->epoch= 30 / 100   loss= 0.27003501809211616\n",
      "-->epoch= 31 / 100   loss= 0.26623117435434834\n",
      "-->epoch= 32 / 100   loss= 0.2651769668386215\n",
      "-->epoch= 33 / 100   loss= 0.2636977655036045\n",
      "-->epoch= 34 / 100   loss= 0.2706835979803291\n",
      "-->epoch= 35 / 100   loss= 0.2617991251595607\n",
      "-->epoch= 36 / 100   loss= 0.2628212359817539\n",
      "-->epoch= 37 / 100   loss= 0.26425796964893455\n",
      "-->epoch= 38 / 100   loss= 0.26750994001539574\n",
      "-->epoch= 39 / 100   loss= 0.2661367084955451\n",
      "-->epoch= 40 / 100   loss= 0.2620863916221632\n",
      "-->epoch= 41 / 100   loss= 0.262617011780791\n",
      "-->epoch= 42 / 100   loss= 0.2659653851673546\n",
      "-->epoch= 43 / 100   loss= 0.2617671070064721\n",
      "-->epoch= 44 / 100   loss= 0.26301570160092275\n",
      "-->epoch= 45 / 100   loss= 0.2670175094350848\n",
      "-->epoch= 46 / 100   loss= 0.2655147907007682\n",
      "-->epoch= 47 / 100   loss= 0.2650946377082006\n",
      "-->epoch= 48 / 100   loss= 0.2604300642435609\n",
      "-->epoch= 49 / 100   loss= 0.26240823971547084\n",
      "-->epoch= 50 / 100   loss= 0.263086008107914\n",
      "-->epoch= 51 / 100   loss= 0.2652051341889499\n",
      "-->epoch= 52 / 100   loss= 0.2620505293224434\n",
      "-->epoch= 53 / 100   loss= 0.2643239509484526\n",
      "-->epoch= 54 / 100   loss= 0.2737483259411097\n",
      "-->epoch= 55 / 100   loss= 0.2664855707524506\n",
      "-->epoch= 56 / 100   loss= 0.26294200441671933\n",
      "-->epoch= 57 / 100   loss= 0.26106155562399624\n",
      "-->epoch= 58 / 100   loss= 0.2637128226652147\n",
      "-->epoch= 59 / 100   loss= 0.2614539308787214\n",
      "-->epoch= 60 / 100   loss= 0.2681799680569585\n",
      "-->epoch= 61 / 100   loss= 0.26786278239199496\n",
      "-->epoch= 62 / 100   loss= 0.26520688596230296\n",
      "-->epoch= 63 / 100   loss= 0.2633620848521961\n",
      "-->epoch= 64 / 100   loss= 0.2608002512843797\n",
      "-->epoch= 65 / 100   loss= 0.26224043868720237\n",
      "-->epoch= 66 / 100   loss= 0.26188465122740395\n",
      "-->epoch= 67 / 100   loss= 0.26213709082888276\n",
      "-->epoch= 68 / 100   loss= 0.26549174721400287\n",
      "-->epoch= 69 / 100   loss= 0.26563436232344984\n",
      "-->epoch= 70 / 100   loss= 0.266118541503015\n",
      "-->epoch= 71 / 100   loss= 0.2661659265320308\n",
      "-->epoch= 72 / 100   loss= 0.2601140874630598\n",
      "-->epoch= 73 / 100   loss= 0.25798651490034746\n",
      "-->epoch= 74 / 100   loss= 0.26240612991663514\n",
      "-->epoch= 75 / 100   loss= 0.26719371111453694\n",
      "-->epoch= 76 / 100   loss= 0.26622043963059716\n",
      "-->epoch= 77 / 100   loss= 0.26408990986856823\n",
      "-->epoch= 78 / 100   loss= 0.26603339003582005\n",
      "-->epoch= 79 / 100   loss= 0.2642724109570032\n",
      "-->epoch= 80 / 100   loss= 0.2621912311843797\n",
      "-->epoch= 81 / 100   loss= 0.26435547213811905\n",
      "-->epoch= 82 / 100   loss= 0.2630427759758463\n",
      "-->epoch= 83 / 100   loss= 0.25868233420903897\n",
      "-->epoch= 84 / 100   loss= 0.2632463362688735\n",
      "-->epoch= 85 / 100   loss= 0.2590099546502299\n",
      "-->epoch= 86 / 100   loss= 0.2626434545953873\n",
      "-->epoch= 87 / 100   loss= 0.26182117463665083\n",
      "-->epoch= 88 / 100   loss= 0.2616152724079255\n",
      "-->epoch= 89 / 100   loss= 0.2602085634846517\n",
      "-->epoch= 90 / 100   loss= 0.2619337540402401\n",
      "-->epoch= 91 / 100   loss= 0.2574983578700683\n",
      "-->epoch= 92 / 100   loss= 0.26070978534831185\n",
      "-->epoch= 93 / 100   loss= 0.2654762543310023\n",
      "-->epoch= 94 / 100   loss= 0.26537500276530046\n",
      "-->epoch= 95 / 100   loss= 0.2614043697599857\n",
      "-->epoch= 96 / 100   loss= 0.2634460663461386\n",
      "-->epoch= 97 / 100   loss= 0.26315202803533394\n",
      "-->epoch= 98 / 100   loss= 0.2612421352933352\n",
      "-->epoch= 99 / 100   loss= 0.26596091681821143\n",
      "-->epoch= 100 / 100   loss= 0.26605073758138925\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.01\n",
    "net = createNetwork()\n",
    "data = readDatasetFromCSV(trainFileName)\n",
    "lossPlot=[]\n",
    "a=[0, 1, 2]\n",
    "b=[0, 1, 2]\n",
    "for it in range(100):\n",
    "    shufData, shufOutput = shuffleData(data)\n",
    "    sumLoss=0.0\n",
    "    for i in range(len(shufData)):\n",
    "        #adding one dropout unit to both the hidden layers\n",
    "        dropout=[np.random.choice(a, 1, replace=False)[0], np.random.choice(b, 1, replace=False)[0]]\n",
    "#         dropout = np.random.choice(a, 1)[0]\n",
    "        observedOutput, loss, target, nt = runForwardPropogation(net, shufData[i], shufOutput[i], dropout)\n",
    "        sumLoss+=loss\n",
    "        net = runBackwardPropogation(nt, target, shufData[i], learningRate, dropout)\n",
    "    sumLoss = sumLoss/len(shufData)\n",
    "    print(\"-->epoch=\", it+1, \"/ 100   loss=\", sumLoss)\n",
    "#     for layer in net:\n",
    "#         print(layer)\n",
    "#     print(\"\\n\\n\")\n",
    "#     learningRate-=0.0005\n",
    "    lossPlot.append(sumLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Weights\n",
      "\n",
      "[0.4162074294295555, -1.9289559873326374]\n",
      "[-0.37267739624319557, 1.4195455716890684]\n",
      "[-0.40321018339727693, 1.4748215570751892]\n",
      "\n",
      "\n",
      "[-0.0372679460151482, 1.0723217964055498, 1.0439124669005106]\n",
      "[-0.03325183661899581, 0.9359570360585597, 0.9001811839159967]\n",
      "[1.6682641604993644, -0.24451828810708867, -0.15553376638946506]\n",
      "\n",
      "\n",
      "[1.193873971160739, 1.4031135252658031, -0.38466730130131227]\n",
      "[-0.4277162080582441, -0.31205590237363756, 1.895162364318533]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned Weights\\n\")\n",
    "for layer in net:\n",
    "#     print(layer)\n",
    "    for neuron in layer:\n",
    "        print(neuron['w'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j=[]\n",
    "for i in range(100):\n",
    "    j.append(i)\n",
    "plt.plot(np.asarray(j), np.asarray(lossPlot))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropogationOnTestData(network, data):\n",
    "#     print(network)\n",
    "    currentData = data\n",
    "    layerCount=0\n",
    "    softmaxInputs=[]\n",
    "    for layer in network:\n",
    "        layerCount+=1\n",
    "        activatedValues = []\n",
    "        for node in layer:\n",
    "#             print(node['w'])\n",
    "            prod = dotProduct(node['w'], currentData)\n",
    "#             print(prod)\n",
    "            if(layerCount!=3):\n",
    "#                 if layerCount==1:\n",
    "                node['o'] = reluActivationFunction(prod)*(2/3)\n",
    "#                 else:\n",
    "#                 node['o'] = reluActivationFunction(prod)\n",
    "#                 print(node['o'])\n",
    "                activatedValues.append(node['o'])\n",
    "            elif(layerCount==3):\n",
    "                softmaxInputs.append(prod)\n",
    "#                 print(\"Softmax:\", softmaxInputs)\n",
    "                if(len(softmaxInputs) == 2):\n",
    "                    activatedValues = softmaxActivationFunction(softmaxInputs)\n",
    "#                     print(\"activated: \", activatedValues)\n",
    "                    layer[0]['o'] = activatedValues[0]\n",
    "                    node['o'] = activatedValues[1]\n",
    "        currentData = activatedValues\n",
    "#     print(\"Summ Current Data: \", currentData[0] + currentData[1])\n",
    "    return currentData, network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runForwardPropogationOnTestData(nn, inputData, rowOutput):\n",
    "    fwdOutput, network = forwardPropogationOnTestData(nn, inputData)\n",
    "#     print([trainData[0][:1], fwdOutput])\n",
    "    loss = 0\n",
    "    targetOutput=[]\n",
    "    if(rowOutput == 1):\n",
    "        targetOutput = [0, 1]\n",
    "    elif (rowOutput == 0):\n",
    "        targetOutput = [1, 0]\n",
    "    for i in range(2):\n",
    "        loss += pow((targetOutput[i] - fwdOutput[i]), 2)\n",
    "    return fwdOutput, loss, targetOutput, network\n",
    "    print(loss)\n",
    "# print(nn)\n",
    "#backwardPropogation(nn, targetOutput)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "   Total in test set: 1250\n",
      "   Correctly predicted: 1071\n",
      "   Accuracy:  85.68 %\n",
      "   Precision:  0.8031746031746032\n",
      "   Recall:  0.9019607843137255\n",
      "   F1-Score:  0.8497061293031066\n"
     ]
    }
   ],
   "source": [
    "### Running on test data\n",
    "testData = readDatasetFromCSV(testFileName)\n",
    "testInput=[]\n",
    "testOutput=[]\n",
    "for row in testData:\n",
    "    testInput.append(row[1:])\n",
    "    testOutput.append(row[0])\n",
    "truePositive=0\n",
    "trueNegative=0\n",
    "falsePositive=0\n",
    "falseNegative=0\n",
    "for i in range(len(testInput)):\n",
    "    o, l, tar, netw = runForwardPropogationOnTestData(net, testInput[i], testOutput[i])\n",
    "#     print(o, testOutput[i])\n",
    "    if(testOutput[i]==0):\n",
    "        if (o[0]>o[1]):\n",
    "            trueNegative +=1\n",
    "        else:\n",
    "            falseNegative+=1\n",
    "    elif(testOutput[i]==1):\n",
    "        if (o[0]<o[1]):\n",
    "            truePositive +=1\n",
    "        else:\n",
    "            falsePositive+=1\n",
    "accuracy = ((truePositive + trueNegative) / len(testInput))*100\n",
    "precision=(truePositive)/(truePositive+falsePositive)\n",
    "recall=(truePositive)/(truePositive+falseNegative)\n",
    "f1score=2*((precision*recall)/(precision+recall))\n",
    "print(\"Test Metrics:\")\n",
    "print(\"   Total in test set:\", len(testInput))\n",
    "print(\"   Correctly predicted:\", truePositive+trueNegative)\n",
    "print(\"   Accuracy: \", accuracy,\"%\")\n",
    "print(\"   Precision: \", precision)\n",
    "print(\"   Recall: \", recall)\n",
    "print(\"   F1-Score: \", f1score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = readDatasetFromCSV(trainFileName)\n",
    "# net = createNetwork()\n",
    "# firstRow=data[0][1:]\n",
    "# op=data[0][0]\n",
    "# a=[0, 1, 2]\n",
    "# v=np.random.choice(a, 1)[0]\n",
    "# # print(net)\n",
    "# print(firstRow, op)\n",
    "# print('drop:',v)\n",
    "# for n in net:\n",
    "#     print(n)\n",
    "# observedOutput, loss, target, nt = runForwardPropogation(net, firstRow, op, v)\n",
    "# print('\\n\\n')\n",
    "# for n in net:\n",
    "#     print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=[0, 1, 2]\n",
    "# b=[0, 1, 2]\n",
    "# adrop = np.random.choice(a, 1)[0]\n",
    "# bdrop = np.random.choice(1, 1)[0]\n",
    "# print([adrop, bdrop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
